<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Icon Lab</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>


	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<h1>Intelligent Construction Lab</h1>
					</header>

				
				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								
								<h2 style="text-align:center;">Towards Optimal Control of Air Handling Units using Deep Reinforcement Learning and Recurrent Neural Network</h2>								
								<div class="image main">
									<img src="../images/HVAC_1.png" />
									<br>
									<figcaption style="text-align:center;font-weight:bold">  Figure 1. Overview of the proposed framework for optimal HVAC control, one-time data flows are represented using dashed arrows and repeated data flows are in solid bold arrows.</figcaption>
								</div>

								<p>
									<b>Abstract: </b>
									Optimal control of heating, ventilation and air conditioning systems (HVACs) aims to minimize the energy consumption of equipment while maintaining the thermal comfort of occupants. Traditional rule-based control methods are not optimized for HVAC systems with continuous sensor readings and actuator controls. Recent developments in deep reinforcement learning (DRL) enabled control of HVACs with continuous sensor inputs and actions, while eliminating the need of building complex thermodynamic models. DRL control includes an environment, which approximates real-world HVAC operations; and an agent, that aims to achieve optimal control over the HVAC. Existing DRL control frameworks use simulation tools (e.g., EnergyPlus) to build DRL training environments with HVAC systems information, but oversimplify building geometrics. This study proposes a framework aiming to achieve optimal control over Air Handling Units (AHUs) by implementing long-short-term-memory (LSTM) networks to approximate real-world HVAC operations to build DRL training environments. The framework also implements state-of-the-art DRL algorithms (e.g., deep deterministic policy gradient) for optimal control over the AHUs. Three AHUs, each with two-years of building automation system (BAS) data, were used as testbeds for evaluation. Our LSTM-based DRL training environments, built using the first year’s BAS data, achieved an average mean square error of 0.0015 across 16 normalized AHU parameters. When deployed in the testing environments, which were built using the second year’s BAS data of the same AHUs, the DRL agents achieved 27% to 30% energy saving comparing to the actual energy consumption, while maintaining the predicted percentage of discomfort (PPD) at 10%. 
								</p>

								<ul class="actions">
									<li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0360132319307474" class="button">Paper Link</a></li>
									<li><a href="../index.html" class="button right">Back</a></li>
								</ul>



							</section>

					</div>


				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; ICon Lab</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li></ul>
					</div>

			</div>

	</body>
</html>